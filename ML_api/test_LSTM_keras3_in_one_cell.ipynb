{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435caf0-9322-4864-980f-28323a07ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tf.random.set_seed(10) ##\n",
    "\n",
    "### load data\n",
    "dir = 'time_series_top5/'\n",
    "df = pd.read_excel(dir + 'samsung_ts_preprocessed3.xlsx')\n",
    "\n",
    "### split train and test data\n",
    "test_sd = 20200303\n",
    "train = df.loc[df['date'] < test_sd]\n",
    "test = df.loc[df['date'] >= test_sd]\n",
    "\n",
    "### scale for train data\n",
    "target = 'foreign_volume'\n",
    "abs_max = train[target].abs().max() # 1121643\n",
    "train['scaled'] = train[target] / abs_max\n",
    "test['scaled'] = test[target] / abs_max\n",
    "\n",
    "# Define a specific window for training Neural Network\n",
    "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i - history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        labels.append(dataset[i+target_size])\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "df2 = pd.concat([train, test])\n",
    "\n",
    "uni_data = df2['scaled'].values\n",
    "TRAIN_SPLIT = len(train) #4782\n",
    "\n",
    "univariate_past_history = 60 # 30 days\n",
    "univariate_future_target = 0\n",
    "\n",
    "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n",
    "                                     univariate_past_history,\n",
    "                                     univariate_future_target)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "val_steps = len(x_val_uni) / BATCH_SIZE\n",
    "print('val_steps :', val_steps, int(val_steps))\n",
    "\n",
    "# 학습데이터 제공 파이프라인\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()\n",
    "\n",
    "reconstructed_model = tf.keras.models.load_model('simple_lstm_model')\n",
    "\n",
    "# to inference\n",
    "cnt = 0\n",
    "for x, y in val_univariate.take(1):\n",
    "    print(reconstructed_model.predict(x)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
